{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14178294",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: left; margin: 30px 15px 15px 15px;\" src=\"https://upload.wikimedia.org/wikipedia/commons/d/db/Logo_ITESO_normal.jpg\" width=\"150\" height=\"100\" /> \n",
    "\n",
    "\n",
    "# SEGUNDO EXAMEN PARCIAL\n",
    "# MODELO NO LINEAL PARA PRONÓSTICOS\n",
    "\n",
    "## Examen Tema 2\n",
    "## Nombre:m José de Jesús Carbajal Castellanos\n",
    "\n",
    "## Fecha: 25 de marzo del 2025\n",
    "\n",
    "## Por: Oscar David Jaramillo Z."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e0d08-3de8-4b28-9161-d9043d1cd17c",
   "metadata": {},
   "source": [
    "# **Examen de Series de Tiempo con Redes Neuronales**\n",
    "\n",
    "## **Instrucciones Generales**\n",
    "\n",
    "En este examen trabajarás con dos conjuntos de datos diferentes: **univariado** y **multivariado**. Los datos univariados se encuentran en la carpeta `univariate`, y los datos multivariados en la carpeta `multivariate`.\n",
    "\n",
    "Deberás implementar los modelos de redes neuronales **MLP**, **CNN**, **LSTM** y **CNN-LSTM** para realizar predicciones en ambos conjuntos de datos.\n",
    "\n",
    "Deberás justificar tus decisiones y documentar adecuadamente tu código y procedimientos.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Conjunto de Datos**\n",
    "\n",
    "### **1. Datos Univariados**\n",
    "\n",
    "- **Archivos:**\n",
    "  - `Hourly-train.csv`: Datos históricos de series de tiempo horarias del conjunto M4.\n",
    "  - `m4_info.csv`: Metadatos que incluyen información como la frecuencia de medición, horizonte de predicción y fecha de inicio.\n",
    "- **Descripción:**\n",
    "  - Cada fila de `Hourly-train.csv` representa una serie de tiempo, y cada columna representa un paso de tiempo.\n",
    "  - El archivo `m4_info.csv` contiene información adicional como:\n",
    "    - **Frecuencia:** Frecuencia de las mediciones (anual, trimestral, mensual, semanal, diaria u horaria).\n",
    "    - **Horizonte:** Número de pasos a predecir para cada serie.\n",
    "    - **Fecha de inicio:** Fecha de la primera medición.\n",
    "    -  Un ejemplo del contenido de este archivo se muestra a continuación:\n",
    "\n",
    "| M4id   | category   |   Frequency |   Horizon | SP     | StartingDate   |\n",
    "|:-------|:-----------|------------:|----------:|:-------|:---------------|\n",
    "| Y1     | Macro      |           1 |         6 | Yearly | 01-01-79 12:00 |\n",
    "\n",
    "   Lo que interpretamos como que la Serie de tiempo $Y1$ tiene una frecuencia anual entre mediciones y las mediciones empiezan el `01-01-79 12:00`. El horizonte que debe predecir esta serie de tiempo es 6 pasos al futuro.\n",
    "Estos datos serán relevantes para poder generar el índice de fechas y también que cada modelo debe de generar una predicción conforme al `Horizont` especificado.\n",
    "- **Series asignadas por estudiante:** Cada estudiante deberá generar predicciones para las siguientes series de datos:\n",
    "\n",
    "| data                                     | Student                             |\n",
    "|:-----------------------------------------|:------------------------------------|\n",
    "| ['H404', 'H275', 'H64', 'H228', 'H38']   | CARBAJAL CASTELLANOS, JOSE DE JESUS |\n",
    "---\n",
    "\n",
    "### **2. Datos Multivariados**\n",
    "\n",
    "- **Archivo:** `Daily Demand Forecasting Orders`.\n",
    "- **Descripción:**\n",
    "  - Contiene 60 filas (días) y 13 columnas (atributos).\n",
    "  - Objetivo: Predecir el total de pedidos diarios (`Target`) utilizando los demás atributos como variables predictoras.\n",
    "- **Atributos:**\n",
    "  - Los atributos en este conjunto de datos son los siguientes:\n",
    "\n",
    "        Week of the month: La semana del mes (1 a 5).\n",
    "        Day of the week (Monday to Friday): El día de la semana (2 a 6).\n",
    "        Non-urgent order: El número de pedidos no urgentes.\n",
    "        Urgent order: El número de pedidos urgentes.\n",
    "        Order type A: El número de pedidos de tipo A.\n",
    "        Order type B: El número de pedidos de tipo B.\n",
    "        Order type C: El número de pedidos de tipo C.\n",
    "        Fiscal sector orders: El número de pedidos del sector fiscal.\n",
    "        Orders from the traffic controller sector: El número de pedidos del sector controlador de tráfico.\n",
    "        Banking orders (1): El número de pedidos bancarios (1).\n",
    "        Banking orders (2): El número de pedidos bancarios (2).\n",
    "        Banking orders (3): El número de pedidos bancarios (3).\n",
    "        Target (Total orders): El total de pedidos (objetivo).\n",
    "\n",
    "---\n",
    "\n",
    "## **Tareas y Requisitos**\n",
    "\n",
    "Para ambos conjuntos de datos (univariado y multivariado), realiza las siguientes tareas para cada red neuronal (MLP, CNN, LSTM y CNN-LSTM):\n",
    "\n",
    "### **1. Análisis de Datos (20%)**\n",
    "\n",
    "- **Carga los datos** y realiza una visualización clara de las series asignadas o los atributos del conjunto de datos.\n",
    "- Realiza las transformaciones o preprocesamiento que consideres necesarios.\n",
    "- Justifica tus decisiones de preprocesamiento y explica cualquier análisis relevante que realices.\n",
    "\n",
    "### **2. División de Datos (10%)**\n",
    "\n",
    "- Divide los datos en conjuntos de entrenamiento, validación y prueba.\n",
    "- **Univariado:**\n",
    "  - Crea índices de tiempo usando el archivo `m4_info.csv`.\n",
    "  - Genera el horizonte de predicción basado en la columna `Horizon` asignada a cada serie.\n",
    "- **Multivariado:**\n",
    "  - Divide las filas en un 70%-15%-15% (entrenamiento, validación, prueba).\n",
    "\n",
    "### **3. Creación de Modelos (30%)**\n",
    "\n",
    "- **Diseña las redes neuronales** utilizando MLP, CNN, LSTM y CNN-LSTM:\n",
    "  - Implementa al menos **tres arquitecturas diferentes** para cada modelo.\n",
    "  - Selecciona la estructura que arroje mejores resultados.\n",
    "- Justifica la elección de las capas ocultas, funciones de activación, optimizadores y otras configuraciones.\n",
    "- Discute los resultados obtenidos y menciona posibles formas de mejorar el rendimiento.\n",
    "\n",
    "### **4. Evaluación del Modelo (20%)**\n",
    "\n",
    "- Evalúa los modelos en el conjunto de prueba.\n",
    "- Compara los pronósticos con los valores reales:\n",
    "  - Si realizaste alguna transformación en los datos (como normalización), revierte las transformaciones antes de la comparación.\n",
    "- Mide la precisión del modelo utilizando métricas adecuadas como:\n",
    "  - **RMSE, MAE, MAPE, o R².**\n",
    "\n",
    "### **5. Optimización con Optuna (15%)**\n",
    "\n",
    "- Implementa **Optuna** para ajustar los hiperparámetros del modelo:\n",
    "  - Ajusta al menos los siguientes hiperparámetros:\n",
    "    - Número de capas, número de unidades, tasa de aprendizaje, tipo de optimizador y funciones de activación.\n",
    "  - Evalúa el modelo optimizado en el conjunto de prueba.\n",
    "- Documenta los cambios en el rendimiento antes y después de la optimización.\n",
    "\n",
    "---\n",
    "\n",
    "## **Formato y Presentación (5%)**\n",
    "\n",
    "1. **Estructura del Trabajo:**\n",
    "   - Introducción a los datos y al modelo.\n",
    "   - Explicación del preprocesamiento realizado.\n",
    "   - Descripción y justificación de las arquitecturas probadas.\n",
    "   - Análisis de resultados antes y después de la optimización.\n",
    "2. **Código:**\n",
    "   - Bien comentado y estructurado.\n",
    "   - Justifica cada paso del código con explicaciones claras.\n",
    "3. **Gráficos:**\n",
    "   - Incluye gráficos de las series de tiempo, visualización de errores y desempeño del modelo.\n",
    "4. **Conclusión:**\n",
    "   - Resume tus hallazgos, dificultades encontradas y posibles mejoras.\n",
    "\n",
    "---\n",
    "\n",
    "**¡Éxito con tu examen!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb78bd",
   "metadata": {},
   "source": [
    "# Datos univariados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcadd3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import univariate_data_analysis, load_data, index_date\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb99e462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info Filtered:\n",
      "       M4id category  Frequency  Horizon      SP    StartingDate\n",
      "99623   H38    Other         24       48  Hourly  01-07-15 12:00\n",
      "99649   H64    Other         24       48  Hourly  01-07-15 12:00\n",
      "99813  H228    Other         24       48  Hourly  15-05-10 12:00\n",
      "99860  H275    Other         24       48  Hourly  02-01-10 12:00\n",
      "99989  H404    Other         24       48  Hourly  06-01-17 12:00\n",
      "\n",
      "Filtered Data (First Rows):\n",
      "V1 Step  H404  H275     H64  H228     H38\n",
      "0    V2  27.0  15.3  2777.0  12.4  3648.0\n",
      "1    V3  22.0  15.0  2886.0  11.7  3658.0\n",
      "2    V4  25.0  14.7  2811.0  11.1  3608.0\n",
      "3    V5  25.0  14.4  2648.0  10.7  3493.0\n",
      "4    V6  14.0  14.3  2618.0  10.3  3374.0\n"
     ]
    }
   ],
   "source": [
    "df_filtered, df_info_filtered = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b90070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_date(ts):\n",
    "    # Get starting date\n",
    "    starting_date = df_info_filtered[df_info_filtered['M4id'] == ts]['StartingDate'].iloc[0]\n",
    "    \n",
    "    # Create a range of datetime values starting from `starting_date`, with hourly frequency\n",
    "    date_range = pd.date_range(start=starting_date, periods=len(df_filtered[ts]), freq='H')\n",
    "    \n",
    "    # Assign the generated date range as an index to the dataframe\n",
    "    df_filtered[ts].index = date_range\n",
    "    \n",
    "    return df_filtered[ts].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d967fb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_nans(ts):\n",
    "    nan_indices = ts[ts.isna()].index.tolist()\n",
    "    has_nans = len(nan_indices) > 0\n",
    "    return has_nans, nan_indices\n",
    "\n",
    "#check_nans(df_filtered['H38'])\n",
    "#check_nans(df_filtered['H38'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ae2fa6",
   "metadata": {},
   "source": [
    "Podemos ver que hay nulos, pero por la forma del dataset, ya que sólo son series con menos registros, todos los nulos están juntos y al final, así que los dropearemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f448fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **MLP**, **CNN**, **LSTM** y **CNN-LSTM** \n",
    "\n",
    "def univariate_data_analysis():\n",
    "    return ...\n",
    "\n",
    "def univariate_data_split():\n",
    "    return ...\n",
    "\n",
    "def univariate_data_modeling():\n",
    "    return ...\n",
    "\n",
    "def univariate_data_eval():\n",
    "    return ...\n",
    "\n",
    "def univariate_optunal():\n",
    "    return ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bce520",
   "metadata": {},
   "source": [
    "\n",
    "Para ambos conjuntos de datos (univariado y multivariado), realiza las siguientes tareas para cada red neuronal (MLP, CNN, LSTM y CNN-LSTM):\n",
    "\n",
    "### **1. Análisis de Datos (20%)**\n",
    "\n",
    "- **Carga los datos** y realiza una visualización clara de las series asignadas o los atributos del conjunto de datos.\n",
    "- Realiza las transformaciones o preprocesamiento que consideres necesarios.\n",
    "- Justifica tus decisiones de preprocesamiento y explica cualquier análisis relevante que realices.\n",
    "\n",
    "### **2. División de Datos (10%)**\n",
    "\n",
    "- Divide los datos en conjuntos de entrenamiento, validación y prueba.\n",
    "- **Univariado:**\n",
    "  - Crea índices de tiempo usando el archivo `m4_info.csv`.\n",
    "  - Genera el horizonte de predicción basado en la columna `Horizon` asignada a cada serie.\n",
    "- **Multivariado:**\n",
    "  - Divide las filas en un 70%-15%-15% (entrenamiento, validación, prueba).\n",
    "\n",
    "### **3. Creación de Modelos (30%)**\n",
    "\n",
    "- **Diseña las redes neuronales** utilizando MLP, CNN, LSTM y CNN-LSTM:\n",
    "  - Implementa al menos **tres arquitecturas diferentes** para cada modelo.\n",
    "  - Selecciona la estructura que arroje mejores resultados.\n",
    "- Justifica la elección de las capas ocultas, funciones de activación, optimizadores y otras configuraciones.\n",
    "- Discute los resultados obtenidos y menciona posibles formas de mejorar el rendimiento.\n",
    "\n",
    "### **4. Evaluación del Modelo (20%)**\n",
    "\n",
    "- Evalúa los modelos en el conjunto de prueba.\n",
    "- Compara los pronósticos con los valores reales:\n",
    "  - Si realizaste alguna transformación en los datos (como normalización), revierte las transformaciones antes de la comparación.\n",
    "- Mide la precisión del modelo utilizando métricas adecuadas como:\n",
    "  - **RMSE, MAE, MAPE, o R².**\n",
    "\n",
    "### **5. Optimización con Optuna (15%)**\n",
    "\n",
    "- Implementa **Optuna** para ajustar los hiperparámetros del modelo:\n",
    "  - Ajusta al menos los siguientes hiperparámetros:\n",
    "    - Número de capas, número de unidades, tasa de aprendizaje, tipo de optimizador y funciones de activación.\n",
    "  - Evalúa el modelo optimizado en el conjunto de prueba.\n",
    "- Documenta los cambios en el rendimiento antes y después de la optimización.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2a4ac",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b7126e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b45ef11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3214cb13",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fb7922",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#808080; background:#fff;\">\n",
    "Created with Jupyter by Oscar David Jaramillo Zuluaga.\n",
    "</footer>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
